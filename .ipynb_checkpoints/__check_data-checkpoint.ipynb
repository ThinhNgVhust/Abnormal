{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import sys\n",
    "sys._enablelegacywindowsfsencoding()\n",
    "from scipy.signal import find_peaks, peak_widths\n",
    "import statistics\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal\n",
    "titles = \"__csv_ch_a_l\\\\normal\\\\\"\n",
    "\n",
    "feature_normal = []\n",
    "label_normal = []\n",
    "for n in os.listdir(titles):\n",
    "    columns = []\n",
    "    all_feature = []\n",
    "    #title = titles + \"/\" + n\n",
    "    title = titles + n\n",
    "    \n",
    "    with open(title) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        # get data follow column\n",
    "        for idx, row in enumerate (reader):\n",
    "            # read data from row 11 to row 90 (80 features for each channel)\n",
    "            if (10 < idx <= 90):\n",
    "                #print(idx)\n",
    "                if idx == 11:\n",
    "                    for i in range(12):\n",
    "                        columns.append([int(row[i])])\n",
    "                else:\n",
    "                    for i in range(12):\n",
    "                        columns[i].append(int(row[i]))\n",
    "            \n",
    "            \"\"\"\n",
    "            if idx == 0:\n",
    "                for i in range(12):\n",
    "                    columns.append([int(row[i])])\n",
    "            else:\n",
    "                for i in range(12):\n",
    "                    columns[i].append(int(row[i]))\n",
    "            \"\"\"\n",
    "    for col_i in columns:\n",
    "        all_feature.extend(col_i)\n",
    "        \n",
    "    feature_normal.append(all_feature)\n",
    "    label_normal.append(0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabnormal\n",
    "titles = \"__csv_ch_a_l\\\\abnormal\\\\\"\n",
    "\n",
    "feature_abnormal = []\n",
    "label_abnormal = []\n",
    "for n in os.listdir(titles):\n",
    "    columns = []\n",
    "    all_feature = []\n",
    "    #title = titles + \"/\" + n\n",
    "    title = titles + n\n",
    "    \n",
    "    with open(title) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        # get data follow column\n",
    "        for idx, row in enumerate (reader):\n",
    "            # read data from row 11 to row 90 (80 features for each channel)\n",
    "            if (10 < idx <= 90):\n",
    "                #print(idx)\n",
    "                if idx == 11:\n",
    "                    for i in range(12):\n",
    "                        columns.append([int(row[i])])\n",
    "                else:\n",
    "                    for i in range(12):\n",
    "                        columns[i].append(int(row[i]))\n",
    "            \"\"\"\n",
    "            if idx == 0:\n",
    "                for i in range(12):\n",
    "                    columns.append([int(row[i])])\n",
    "            else:\n",
    "                for i in range(12):\n",
    "                    columns[i].append(int(row[i]))\n",
    "            \"\"\"\n",
    "    for col_i in columns:\n",
    "        all_feature.extend(col_i)\n",
    "        \n",
    "    feature_abnormal.append(all_feature)\n",
    "    label_abnormal.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data : testing data 8:2\n",
    "N_normal_training = int(0.8 * len(feature_normal))\n",
    "N_abnormal_training = int(0.8 * len(feature_abnormal))\n",
    "N_ROW_TRAIN = N_abnormal_training + N_normal_training\n",
    "#N_COL_TRAIN = 1260\n",
    "N_COL_TRAIN = 960\n",
    "\n",
    "matrix_feature_train = np.zeros((N_ROW_TRAIN, N_COL_TRAIN), dtype = np.float32)\n",
    "matrix_label_train = []\n",
    "\n",
    "for m in range(N_abnormal_training):\n",
    "    matrix_feature_train[m, :len(feature_abnormal[m])] = feature_abnormal[m]\n",
    "    matrix_label_train.append(label_abnormal[m])\n",
    "for m in range(N_normal_training):\n",
    "    matrix_feature_train[m + N_abnormal_training, :len(feature_normal[m])] = feature_normal[m]\n",
    "    matrix_label_train.append(label_normal[m])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data for training\n",
    "# set up training\n",
    "from sklearn import svm\n",
    "import pickle\n",
    "\n",
    "clf = svm.SVC(kernel = 'rbf', C = 64, gamma = 0.00000008)\n",
    "clf.fit(matrix_feature_train, matrix_label_train)\n",
    "\n",
    "# save model\n",
    "filename = \"models\\model.xml\"\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "# load model from disk to evaluate\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result_train = loaded_model.score(matrix_feature_train, matrix_label_train)\n",
    "print(\"train accuracy :\", result_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# test set\n",
    "N_normal_testing = len(feature_normal) - N_normal_training\n",
    "N_abnormal_testing = len(feature_abnormal) - N_abnormal_training\n",
    "\n",
    "M_ROW_TEST = N_normal_testing + N_abnormal_testing\n",
    "#N_COL_TEST =  1260\n",
    "N_COL_TEST =  960\n",
    "matrix_feature_test = np.zeros((M_ROW_TEST,N_COL_TEST),dtype = np.float32)\n",
    "matrix_label_test = []\n",
    "for m in range(N_abnormal_testing):\n",
    "    matrix_feature_test[m,:len(feature_abnormal[m+ N_abnormal_training])] = feature_abnormal[m+ N_abnormal_training]\n",
    "    matrix_label_test.append(label_abnormal[m+ N_abnormal_training])\n",
    "for m in range(N_normal_testing):\n",
    "    matrix_feature_test[m+N_abnormal_testing,:len(feature_normal[m+N_normal_training])] = feature_normal[m+N_normal_training]\n",
    "    matrix_label_test.append(label_normal[m + N_normal_training])\n",
    "    \n",
    "result_test = loaded_model.score(matrix_feature_test, matrix_label_test)\n",
    "print(\"test accuracy:\",result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
